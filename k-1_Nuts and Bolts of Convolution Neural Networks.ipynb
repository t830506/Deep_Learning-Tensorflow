{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unahsu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting dataset/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting dataset/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting dataset/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting dataset/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "dest_directory = 'dataset/mnist'\n",
    "# check the directory\n",
    "if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "# import data\n",
    "mnist = input_data.read_data_sets(\"dataset/mnist/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model (Softmax Regression)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None, 784])  # flatten into vector of 28 x 28 = 784\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])  # true answers\n",
    "W = tf.Variable(tf.zeros([784, 10]))  # Weights\n",
    "b = tf.Variable(tf.zeros([10]))  # bias\n",
    "y_pred = tf.matmul(x, W) + b  # y = Wx + b\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_true, \n",
    "                                            logits=y_pred))  # our loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(\n",
    "    cross_entropy)  # our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.8%\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize the variables we created\n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    # run the training step 1000 times\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        # feed training data x and y_ for training\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y_true: batch_ys\n",
    "        })  \n",
    "\n",
    "    # Testing\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy = sess.run(accuracy_op, feed_dict={\n",
    "          x: mnist.test.images,\n",
    "          y_true: mnist.test.labels\n",
    "    })\n",
    "    # feed our testing data for testing\n",
    "    print('Accuracy: %.1f%%' % (accuracy * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Convolutional Network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our convolutions uses a stride of one and are zero padded so that the output is the same size as the input.\n",
    "# Our pooling is plain old max pooling over 2x2 blocks.\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [batch_size, height, width, channel]\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # (filter_height, filter_width, number of input channels, number of output channels)\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# convolve x_image with the weight tensor, add the bias, then apply the ReLU function\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# and finally max pool \n",
    "h_pool1 = max_pool_2x2(h_conv1) # It will reduce the image size to \"14x14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second Convolutional Layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2) # It will reduce the image size to \"7x7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Densely Connected Layer\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) \n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) # flatten\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Readout Layer\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_conv)) # our loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) # our optimizer\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "\n",
    "# Re-import data for initializing batch\n",
    "mnist = input_data.read_data_sets(\"dataset/mnist\", one_hot=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(\n",
    "        tf.global_variables_initializer())  # initialize the variables we created\n",
    "    # run the training step 20000 times\n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0],\n",
    "                y_true: batch[1],\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            print('step %d, training accuracy %.1f%%' % (i, train_accuracy * 100))\n",
    "        train_step.run(feed_dict={\n",
    "            x: batch[0],\n",
    "            y_true: batch[1],\n",
    "            keep_prob: 0.5\n",
    "        })  # feed into x, y_ and keep_prob for training\n",
    "\n",
    "    print('test accuracy %.1f%%' % (100 * accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images,\n",
    "        y_true: mnist.test.labels,\n",
    "        keep_prob: 1.0\n",
    "    })))  # feed for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors (KNN) on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 128s 1us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# convert class vectors to binary vectors\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAACICAYAAAABDZUdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztXVuMZEd5/v4+fZ37ZWd3Zy+sN+vF\ngHFwjAFLSZTgBAlFSM5DIoWHiEhIfkmkRMoDKG+REom8JHnJiyVIiAQhCJCwAhJCloEYIrCJCSws\nwfbG673Pzs7MTndP37vy0N31f1X0menxzrZndv9Pslx9+pxTdU711nzffytxzsFgMBgAIPNWD8Bg\nMOwf2IJgMBg8bEEwGAwetiAYDAYPWxAMBoOHLQgGg8HDFgSDweBxRwuCiHxYRP5XRF4VkU/u1aAM\n+ws2z/cP5M0GJolIAuAXAD4E4DKAFwF81Dn3s70bnuGths3z/YXsHVz7fgCvOucuAICIfAHAUwBS\nfyiZJOsy2Vz/g/jjxVw4jIS+E2jbuY626fx2p6sfHLUBZBO9t4jei7pAJkNEiY4DQDar13e7wxdP\nui3iBbbb1fF06PpMJqGz9DiPka8Nzwo/CPi+/ADhw3Q6+v66/XHWa3U0m63oqQPsep6TJHGD98bv\ntlAoxOfpSOm5eZyMdrvt2/F7zuVyQ+/F/XObz4mv5/fO/cTXMHjM3OZnTEM8z4y0/oPfbIRh76la\nraLRaGw3zwDubEE4DuASfb4M4APbXZDJ5jB14gwAICnqBLzz6FJw3uyEjjtJ9LxGrezbbVI765tb\nvu2a1eBehxYXfTuf1ckp5LRdmtAfaiYJX/T8Ib2+UW/6dqejE5Wje3W7reD6cqXm21s1vb40OaXX\n0CLGP6BaTa8ForWOfigZ6A+wVNRnSTLh9G6sr+tYOr2x/OC7P8IO2PU8Z7NZHDt2DABQLBb98bNn\nzwbnTU3pO8jn875dqVR8m/+xrK2t+Xaj0Qjutby8PPRevAhNTk76Ni8AAHD06FHf3trS3xP/4+b7\nxovW7du3h45/ZmZm6LPwHxo+Pz6P27wITExM+Ha86Ny8edO3B+/pueeewyi4kwVh2GrzS39CReRp\nAE8DgGRzv3SBYd9j1/M8yl9Fw/7EnSwIlwGcpM8nAFyNT3LOPQPgGQDIFAqu1u79BZ9xc/6cX3no\nweCaw4v63fxkybdfv/i6b7NKOEuS4yc/fjm4V6utf5WLBf1rNTWl983licpGtHCzrIwjk2H5oT/6\nRjNdslSr+teG2U6a7Yb/ojWbzeC7eqvu2/wXokDPz385W06pIwC4PMmfeshktsGu5zmXy7l6vTdW\nZgiPPvpocA3/VZ+b0zn/+c9/7tv8l5jfzQsvvBDcq9XS5+E+Z2dnhx6P6f86sac0KcPvNqb5m5ub\nvh3KzOFygMcyeFcDMEOZnp72bX5+Pifug9lPzKR2wp14GV4EcFZETotIHsAfAXj2Du5n2J+web6P\n8KYZgnOuLSJ/BuAbABIAn3HO/XTPRmbYF7B5vr9wJ5IBzrmvA/j6qOcXE+Adiz0KVswpTequXQjO\nu7g579v/RxK201L6k3SUIrJhnekaADghKz9dI8SN2HvRbIZUeoso19SU0k+h+2aJYuZyoSU9S3aT\nTMJjU8nAxi42tDUjusfj5+sdPYyQLEmyIQF0JEEGkmsUp/Nu57lQKODUqVMAQmq8uroanMc0ncFS\niekw03c28MVgmcGGOL5XTKWrVZWGLF9YPvBvK/aYME2Pf4MDsIGRpUwsGbbzpgzrI+5vmFF01PAC\ni1Q0GAwetiAYDAYPWxAMBoPHHdkQdovDpRz+7F29AJAyBRm5TDk470vnX/ftq01ds47PqE47VNSh\n3+5qO19SdyIANJoa3JOQnm82VaclibY3yxpgAgBJhiLYGqr1CuTCnCyqDSATxVpkZMO3O6QNE3IV\nbm5qnxsben6M4HrStls0rmJR3ZFZCdd7fuZ2o9e+GzU1Z2dn8ZGPfAQAUC7r3Ma6+/nnn/dtdtsd\nPnzYt9ntxq7FUjTPHMSV5nZjbc5BTkCow9mGwf1sF9jEtgoeJ5/HfXLwUAy+nsfFtgEeSxy1yDaJ\nQXu7aEiGMQSDweBhC4LBYPAYq2Rouy5udHpx27/10II/XqmGkuH3Gkpjr7SUsnWIvq9XlRZNFpVW\ntiPKLqIuqCwlFE1RLkG9oS4nppUAkC/o/WpbOs48UTnXVorXihKgEqKM9Sq507a07YLEHpIF2SgE\n2HHik/bTpujIVotlRTi9WXLPdgZjvguSodvt+vj8973vff44x/vH33E8P7sXWUKxCzMOj+ZrmGaz\nq49lxS/NM7kxWebwcb4mpuB8Hj9nGlVn12gsP1jGBQlpKW7T2AXL72YwZnM7GgyGXcMWBIPB4DFW\nybBaaeCfv/0aAKBV13yZ3zw7G5z33pP6+cimUsH/uqJW1qqoxbrL+eeZkH4VSELkiIJPUnJQEM02\nH66RjbrSTO4nQ7S0TTT/9kYYfcfRiZMl7dM5Pd4iNpcknEsfJRrmlBp2iQIW6LnYE9Fohym6s5Pa\n/8rq9f449l4y3Lp1C5///OcBhDSdJQIAvPvd7/ZttrqfO3fOt5ky81hjyzrTZqbg7KVgKs2eDCC0\n4LM0YPmxnZeC783Rpoy0Ogux/OFn4fP4uXgssfzhSMsrV64MHUsajCEYDAYPWxAMBoPHWCVDo+3w\n2q0evfnXl9V6/N2rIbUtEFNOSkqfqlTpqyNE60pE5V14L0c0rUDVhNgSnKUgoVwUzNOmzKk6VUzK\nEM2rU82FXJRnf2RG6dtqRYNvrq3r8+eLHPAyPJkGCCVLs0lWZhoLV1/quqiEmlNvSLef1uRGSm/a\nHVqtFi5fvgwA+NrXvuaP//SnYZIkPx8HAMXJPsPOSUsgAsJaEbdu3fJtpuIxTQ8CvUg+cD9s2Y+v\nP3LkiG+znLh+/frQcfFYYi8BSwAeC1+flvQFhIFVA8lhXgaDwbBr2IJgMBg8xioZRDLI9WPtN7pK\nky5WQ/o1V1Jr6kRWaVKVApjaDQ1kOU655Y12mOeep/j5fJ5LUGkw0gIVWT00rQFTAFBvajDM5at6\n7yzVQ+hSkdOzD3C1MWChqIExN36mlvQ65Vjki0qFWy29V62mdBEIK1ALeSA49l2oSGwrsj43G9rn\n3gsFRSaT8UFETLOZvgOhNZ6DjjhIienvmTNnhh4HQjnB9+IgI/Y4HDp0KLievSEXLmh9jrRKzewh\nAcL6Bt/5zneG3jetbFpcZJXB0oSfmY/z/AOhzNgtjCEYDAYPWxAMBoPHWCVDkhFMD+QAUX7UQvo3\nO6e0fbqga9Ztop+VqraZ1hWLYYqtUKVkx5Q7y/He2n8eocX38IJ6CbJUwm1hSY8XSZbMR2m511eU\nJtda9JycV0B7OTQbNJZ8+CxsKe62KciFzumSSmhHtJq3nOi60dJh3wwymYyn5ywZYirLeyGwfOBg\nGqb8TJM5/XfQ5wBpQT9MuWPL/PHjx32brfx8nGUJSwQAuHRJt65I85KwZyBNSsTjj4OOBuBnicvB\nbbfZz04whmAwGDxsQTAYDB62IBgMBo+x2hAg6i5LEtWAm5EGqnVVA811VAPmKXGp2VYN1qFtnEqR\nDeEGafiExHY2T+45chvW4o1Gb2vp8AXSrSXQfowNKnstoea7uqaRavUuJ6qoraLVVM2ZL6hOzUcl\n3dtUd6FBkYoJ7SLFkZnxPpUtcsn6SMttNjB9sxARr+m5bBqXOgdCdxlrXY7c43M40SkuoTaIjIzB\n/bO2j0vVcQm3tIQoHku87+bVq7qZVdpuU9w/jz8uLcf98DVpG9LGUZvD3JPbbVTL2JEhiMhnRGRF\nRM7RsQUR+aaIvNL///x29zDsf9g8G4DRJMO/APhwdOyTAJ5zzp0F8Fz/s+Fg419g83zfY0fJ4Jz7\njog8EB1+CsBv99ufBfAtAJ/Y6V4igmy+R3uaTaLm3ZDO1Gnz1BbXIAi2SldatEnbwSOi/NNEmxdI\nM0zmtE+uJ+Caocuok9FreKeh9QYll9CmqovzoTuqQ2tug555kigjSwEue9buxC4jkim0lJepUvRE\nSV1Y2Uz4LrYoOnIgOVzf/bjX8zygwdttkMp0OG23JZYZnDQUb8fOrru0SsnbbaTLtHtlZcW3OYqQ\n3YFxPQX+jp+L+0+rsxBHGjL4XfDvj92021VdHkibu111+Yhz7hoA9P9/eIfzDQcTNs/3Ge66UVFE\nngbwNPDLKaOGewc2z/cG3uyCcENElp1z10RkGcBK2onOuWcAPAMA2Vzi6v2aAA2qDtyNqHGjrjSr\nHlB4PW92SpOeGmW1EM/MLwf3Onp00bdLVIG5zRV4qUxaJvoxl4iaVdbUMr3ZVJmyMK8JTLlCGHXW\nampCE1dRbrTYekybcVACVz66l6PNXgt5tTi3GkE5ZTonyvknS3Or0buX626b5vTm5jmbdQOrPUuG\nmOazHIit9gNwOTCuYbG8HM4zf2Y6zvdl+h/TbO6HaxjwGFkmxF6ONG8AH2fJwl6N+F78ntjjkiax\n4khHfrZxbdTyLICP9dsfA/DVN3kfw/6GzfN9hlHcjv8G4L8APCQil0Xk4wA+BeBDIvIKgA/1PxsO\nMGyeDcBoXoaPpnz1O7vtLJ/N4cTRXqmpMtGfayvhPndkwEcmS5bhulL2xWk9fua4yoLFqbDqcquq\nlllO6GkQleS6ARJRyUJRPx87ojn0W6t6r6lp7f/kUaWeAHBpVelnnmKWylWlr8FGHQ2quiwhxc6S\nTOBxTpElm2sodNqhZGg3udRc6NnZy3kuFAp44IEHAIQ0nROAgHSrO1Pj+XkNfXj7298+9HjcT9px\n7i+WDFye7G1ve9vQMXOfg+cb4I033vBtlhlBqT56Rg4UisfCvwf+jjed4T7iBKg42Wk3sNBlg8Hg\nYQuCwWDwGGsuQ6FUwtl3PQIAuHJTDdbtbBjLnad8hOkJynuf0xjz5cNK3w5Nq5U2E+X5c2AT0+wm\n7R9ZKFDOfLS5SYu2Ws/PqMdhYpIsw1myBG+F+1TWaNv7m6tqWXZU3ZkN/TkeYzsMntmi8mp1kjxz\nc/ou+F7rt8Pcgc2KyolabWB93vtiahMTE35TFqbSMTXmoB2uL8CSgen7wkJY3o7B13A/7AJN2/I9\nvp7PS8triCUK123gvAZGWv5BTPE5UIn7WVpaGnqv1VXNtwHCAKZBDQrbDt5gMOwatiAYDAYPWxAM\nBoPHWG0IThK0Cj3XiSuohps/HLoKT86pDWEyr+6ZpePq9pufVQ0/XeSEnnCNazZU35fJVTM1RclF\nFN3X3gptCPU6ufGaqhM7TvupUHnzXF7dVwBQovoGzS11rzaaqt23srTTDtVmKJZC20ra6t2gCMYK\nRV1WqmH032363OxHh96NnZtExLvOODrvxIkTwXlcU5Gj9di9uLioLl1O6InDo9NqHbBtYrsNUtmN\nlxYRyOfENQzYHpJ2r7TdpuL6kOyS5KQptnuwbYGjHoHw+QfX2M5NBoNh17AFwWAweIxVMnThUO27\n9aZnlApmk3AYt25pOaylJaV8syQl8qIUiF2DmVx4rwaVNS8Tzcryxp9ZlSzFUhjBN0Gbrwr1mQiX\ngVf6ObcY7gh0aIk2dc3d8O0aRSoePXrMt1fWVVZ0IpbHY+6QG+kmUcR6Xce1thFSSXZVFnzdhL0v\noeac81SZKX8QkYkwiYglA++qxNIgLVEICJOYmDJz4g9TdpYf8XlM2dMiCnlzVyAs185jY3fkqVOn\nfJufPXYJ8lhY2nCdBi5pf/NmGOnLkiVOnNoJxhAMBoOHLQgGg8FjzDs3ZTA33aNDhYxa48tJWEKq\n2VKaUyMr/9YWJ+fo0LtdPd5ph4+0flupeZXKrs2X1LKbIcnClZ0BIJ/ovSemNLnkV4oqZZbPPuzb\nh06ERYUKFzVqrVZXKieUuLS2plRwZVXpXyGqusw0t000c40i01gBNJvhe61zRFymd+Jud/YZBUmS\n+EQgzuePJQP3zVZzptlsHWeLf1x2jKP1qoE3abhnIvZS8NjYM8HRgbzB6+nTp4Prz53ztWmD/lly\n3LihkpF3p4rlD9dmYMnA1w+reTAAy4lB/xapaDAYdg1bEAwGg8dYJYOIUp3VW0rxGhvXg/POLGpC\nyebKNT2P5EBnizYkIet/J0rWqRBNZio6P891C5TWJVFgU7el9CtDJdwW51Q+cIDNxHRYDyFJlDJP\nl1QmzRxWWnptRasJr97QjWWYbgPA7TXNrc8XKKGKysxtbVGQVETRC1zaq9p7LncXJIOIeErOiT6c\ndAMAJ0+e9G0+L61SM9PkmAIzTed+4urIA8SSgSUI03yWDOwlYFoPpCdE8TNybQXeWCYugcZeA/6O\nPSn8W44lB38eSDGTDAaDYdewBcFgMHiMVTK0O11s9K3+l68rRTw9Ha5LSUPp3yTF829UlUrWaW/D\nyZLS56lSSLM3ynovR9Jgalope7WmlLvVCmPc8xm9Jij5lQxfS1txNBF9rJUpMIrG0uF9GqkCdWMr\nsh632Xqtx7m0WpLoF9mIFrMcytyFgKQB2u02bt3qSZ/XX3/dH4+DeTg2n70BHJvPFnOm4nH8P8sE\n9kywxyAtxwAI5RmPKy3/IM6F4D65bBrLnLS9LOPaCnxvli88xrQ6D/F3u4UxBIPB4GELgsFg8LAF\nwWAweIzVhtBqtnDlSi/aqulo49N8FMHWZN2va9Yt0lpbDdVj1aZqrmq0A1CZdPgRSppBTt059bKe\n00XkjsqoDaMNTnRSbdekCMRqEtoQMrRZ7LFl1dBVSm4SqGY9TqXes6UwAWeTnp9dUEL2jBy5I09S\nPUIA2NxUbVup9Ma8Wk3djOlNo9Fo4MKFCwDC6MI40SauazgAb+rKNgTW/ex2A0LdzolGrLv5vnF9\ngLQaBGwD4LFsp9vZPZkWdcm1ImN7CCdnsX2B+2B35EMPPRRcP7DfAPpe2M25HUbZqOWkiDwvIudF\n5Kci8uf94wsi8k0ReaX///md7mXYv7B5NgCjSYY2gL90zr0TwBMA/lRE3gXgkwCec86dBfBc/7Ph\n4MLm2TDSzk3XAAy2BC+LyHkAxwE8BeC3+6d9FsC3AHxih3uh2XfrNZ1S/s2NkObn87pOtck71qCy\nZXWqdNauU2mpcrxpKNG/glKza6tKMTcrw+k3ALiS0rRFIZcmlVFfua50LCrtgGpF6V+WNnudmtGo\nxeKE3ndhjjbBzUe57DdJslQoapNKz+c5Sq0WlmGvczTeYCx9qrzX8zyINmQXWlwuPK5J4J8nJYmJ\n6Xcc9chgOs1JREzFY9dcWokxlhIXL1707Vgy8L1ZpvBuTywNOIIyjijliEb+jl2VLL9i+cSRnmlu\n0zTsyqgoIg8A+DUA3wdwpP8jGvyYhsaIisjTIvKSiLzUiTLUDPsTdzrPcSai4eBg5AVBRKYAfBnA\nXzjnNnc6fwDn3DPOucedc48n0Upo2H/Yi3mO/+IZDg5G4hMikkPvR/I559xX+odviMiyc+6aiCwD\n2NFc7SDoZHpUrbKuFttXbm4E5zVnKdkjp/Tryi21EjfZep3Tda3TCGnyZFF/nE2i1htr+lu/tqr9\nR3ug4uHTy/qBKLwjKlmvKmWLd366TMlK65tqMW4QlWYqX6mSx0PCf48torVtkkK8C1SbHqBSC6Px\nmBTX+tGRTEP3ap4ZTO3Zyg+ESWG8iDDNZ7bBSTtxpCFv1soy5do1TY7j+8Z45JFHfDtOKhuAqXns\nIWE5wVZ+Po/HHFdKZvCcsJRh+cKyKpYMfM3AG7VnVZelN4pPAzjvnPt7+upZAB/rtz8G4Ksj9WjY\nl7B5NgCjMYRfB/DHAH4iIj/qH/srAJ8C8EUR+TiANwD84d0ZomFMsHk2jORleAHppXl/ZzedOTg0\n+3SuQ0lE1VaYq12jkmhrK1o2aqNCVXeLSt8LlPQihTDIY3Nd6Vu5pvSz02VqrVbZdjek/NdJTpw8\npoFFbkWpcIY2q714VccLAD8896pek+iYJavtLrkmshNKnTvRWDg5qc2vjK53wVSFNDGhRK2C9KSb\nZHrPt6fz7Jyn+mm1DYCQTnM9BLbYsxRgiz0fB8IaAhzMw9Saj8fJSdz/mTNnfJs3q2VZ89prrwXX\nf+973/NtDmZKS0hijwOPMb6ev+Prt6tvwOMceHLijXbTYKHLBoPBwxYEg8HgMeYSaoJCoddlneJC\nJibDElDLJ3UPQJeolXhqWmnS7IyWsFpcXPDtyUmVDwDwgx+86Nu5otK0R96h8d+lyVd8++Uf/Ti4\n/vwvXtex0PpZLCoVnJnTnPvVzTC3vUzG6K2WBkBNTlBthkn1qmRo05i2C2kh00eWTF3yMrBkKOTD\n0lxMk10/f0Jk7/8miIgPDtqu6vKDDz7o20yHuTwZb9rCXgmucwAA3/jGN3ybg3be+973+vbMjJa9\n+/a3vx1c//LLLw99FpYmCwv6O2NPAhDWWmApxDUcuH9+F7Fk4HkaZaOVuARbLIeA0EOxHYwhGAwG\nD1sQDAaDx3j3dux0UOun4Ga7avGfmQ1pUWmSaBrJgRblLCwsKP1yUEv2/EIYWfvY47qJygRRq0ce\nfqdv1ynmf3U1jLvJF7UfDsjdLGtglaM05dv1kK4JpVm7rn7XJCtxjfaf3KJ9KuNYEpdSXZqDpBLy\nOJQrOkZgeI7A3diopdPpeE8B3z+uVMx0muUApxnzcQ6uYSkBAB/84Ad9m3MknnjiCd9mWs9eBSCU\nBtwP518wNY+DgThoKm3beX4uHst24OvZU8A5CnGQE18z8PJY1WWDwbBr2IJgMBg8bEEwGAwe47Uh\ntFso9/e4n86qTsvPhMOoBmWnWGur2269rLo5QxF4k7fDPPnHH/tV327SrkZt2pGJN2E9RDv1AGFJ\nNS7VllAJuI2y1laIowsXZ2izUUo2alKkJut+brcj3ceeoxzVVmjQvbbqXFI+TMBhHTloO4yW9LIb\ntFotn1TEujt2fXFEIo+Ny8NxQhRr6Njt9+STT/o2RyRypCQfP3bsWOr4uX+2u/BYYk2+uLjo2+xS\nTCvpzu34Xvye+Dy+F9sg+Bnj+/l53qvkJoPBcP/AFgSDweAx3khFCIp9ej9P0XmzUdVZ8q6hTjS7\nOEERWRmlZVep5kCrGVKjh8++w7cLtKvRylVNWmm3lXKtl0N3ELPcLcooYlffJLmcZhfCSMlSQd1Z\nk+RerDaU5heozkKZaitslsOoxy5tNtshWphQablChsaIUL6Azsv0IwO3Rkx62Q1ExNNmTkiKowsZ\n7JJjtyHLBE40iushPPbYY77NNJt3juLaCnFtBqbpTMH5OLsm401k+btKSnVslk9cJTouB8f0niVL\nWjXoGMPOs+Qmg8Gwa9iCYDAYPMYqGbJJBnOzPXngukoRk2ijlhbVR3AZtaaXKTowkyX6V1Zr9dKS\nRjYCwOtU2qpVUzr+jgcf8G0uR3arFm32WlT6mptQaj8zq1F32bxKhm4mfKUNKgGHnNK/XFGfcWJC\n+5g8pGOZqYbRcFzfYJM8G+WKRqpNTan8ykfJRC3a3CbXp6+VN65jr5HNZr3VnSlvXJqMreZMzdn7\nwPSfPQu8GQsAnD9/3reZpr/nPe/xbabScXQfU35uc0QkRyPGFJyfjZ+FZQInN3EEJsuHGCwn+L2w\n/OJxAaGcGiRHcSm57WAMwWAweNiCYDAYPMYqGZKMYLbvXeiQxb3ejCroFpWylcn6vMX73BGVnKCc\n8emZ0MrPwTnNjtL01XWqukxVn+eOnAyun1rQAJY81SAQyt9f29B7ZTMhfcuRhNhq6fg3uG4C1S2Y\nKCn1nFwI5Y/rKOWtkJdiblHHVSK6m43qIWyR5Or06yY4CTcs2QskSeITmdL2ZgTCMmJM4bnNkoG9\nD+y9AEIPArdv3NCSdry/YRyYdOSIlsfjGgTcP5dpS6vMDIReCpY5fA3LkqUoGI5lVlqiF7+LuB4C\nS4uBTLJ6CAaDYdewBcFgMHiMN5eh20Gt0rOoHj1CdDiKs75BQSPtjlLjCbKgZ4gCMUm/cukNMPLL\nGkDy8MNaG2GDaH43r/ctTIVUdGpGrblCluWwBJaOv9EItzHLdPTzBG0oI5Mkc0pK+SqbSvfqtbCe\nwfSsxss3Ka9iku51+ZLS4s2NMOBlelKt3PlSj7J2h5TbulN0Oh1vOT95UiVYHE/Plm/O4WdrPFvz\n+fpXX9Vq1vF3H/jAB3yb6xnwnHEtBiAsj8b0Oq3OQSx/gvJ2dA3XgGCan7blfTwWlh88Zn7+eM9M\n9kAMZNmo2+uNslFLUUR+ICL/098m/K/7x0+LyPf724T/u4ikiyrDvofNswEYTTI0ADzpnHsPgEcB\nfFhEngDwdwD+ob9N+DqAj9+9YRrGAJtnw84LguthYBLP9f9zAJ4E8KX+8c8C+P27MkLDWGDzbABG\n3+w1AfBDAA8C+CcArwHYcM4NRNVlAMdTLuf7IN+PSmy2eJPRUFtmyNWzNKt6ElRr4MYNjbDbolqL\nx5bVNQMACdUNuHZdNevabU1iWq/o9UeXwh2BlhZUj739rJYNZ33PNQzW18Oos9uk42fIBjIxoXpw\nZVVdU/Vp1Zn5bDg9ObI1HDui9gRQzYiZoj5vZTpk94Wsfl480ntPV34YRNjt2TwPdHRaNCIQanqO\nCOR8/kuXLunzkNv59OnTwb24jDsnNLG+5qg/duEBodvx0Ucf9W2uO8AuyJWVsPYm98N2A9b9XMeR\nnzd2YbJL8tSpU77NdhK2R7A7FAhtGCdO9LY0ePHFFzEKRvIyOOc6zrlHAZwA8H4A7xx22rBrReRp\nEXlJRF5qRzsjG/YX9m6e995QaRgPduV2dM5tAPgWgCcAzInIYMk8AeBqyjXPOOced849ns3ufRCM\nYe9x5/M8VueVYQ+x48yJyBKAlnNuQ0RKAH4XPUPT8wD+AMAXMOI24Q7AwEO3TiXCc9FCwZuaCtUg\nyFA9gGmiVdPTKisOLYbRfaCaADkqtRa4OimBqhX9dbt5S92A07NKC8sb6jYqEOWr10P3TpdqELSh\n5128ppLnwgV1IeVzOpZilPRVWdP+61tKZdsd7lPfEZdpA0LJcLtfa6HRL/u+l/MMKO1n91pMjdM2\nNWVpwS5IpuLLy8upfactSNyxV/fbAAACnUlEQVRf7Ia7fl3ng2VKWhl2TqACQpnD1P7ChQu+fe7c\nOd9mWh9HGqZtXJvmOoxLqPG9B+8/Hm8aRlnKlwF8tq8vMwC+6Jz7DxH5GYAviMjfAHgZwKdH6tGw\nX2HzbBhpO/gfA/i1IccvoKczDfcAbJ4NACCjVmPdk85EbgKoAljd6dx7GIewv57/lHNuaefTRofN\nM4ADOs9jXRAAQERecs49PtZO9xHul+e/X54zDQf1+S25yWAweNiCYDAYPN6KBeGZt6DP/YT75fnv\nl+dMw4F8/rHbEAwGw/6FSQaDweAx1gVBRD4sIv8rIq+KyCfH2fe4ISInReR5ETnfry/w5/3jCyLy\nzX59gW+KyPxO9zposHk+uPM8NsnQj4D7BYAPoZc19yKAjzrnfjaWAYwZIrIMYNk5998iMo1eFuHv\nA/gTAGvOuU/1/7HMO+c+8RYOdU9h83yw53mcDOH9AF51zl1wzjXRi41/aoz9jxXOuWvOuf/ut8sA\nzqOXOvwUenUFgHuzvoDN8wGe53EuCMcBXKLPI+XW3wsQkQfQCwv+PoAjzrlrQO/HBOBw+pUHEjbP\nB3iex7kgDCsMf8+7OERkCsCXAfyFc25zp/PvAdg8H+B5HueCcBkA74KSmlt/r0BEcuj9SD7nnPtK\n//CNvu4c6M+VtOsPKGyeeziQ8zzOBeFFAGf7VXzzAP4IwLNj7H+skF5S/6cBnHfO/T199Sx6dQWA\nXdQXOECwee7hQM7zuLMdfw/APwJIAHzGOfe3Y+t8zBCR3wDwnwB+Aq1a8lfo6csvAngbgDcA/KFz\nbm3oTQ4obJ4P7jxbpKLBYPCwSEWDweBhC4LBYPCwBcFgMHjYgmAwGDxsQTAYDB62IBgMBg9bEAwG\ng4ctCAaDweP/Adem7PvSPy2IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115182710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transform an 3-channel image into 1-channel\n",
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r = np.asarray(.3, dtype=dtype)\n",
    "    g = np.asarray(.59, dtype=dtype)\n",
    "    b = np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n",
    "\n",
    "X_train_gray = grayscale(X_train)\n",
    "X_test_gray = grayscale(X_test)\n",
    "\n",
    "# plot a randomly chosen image\n",
    "img = round(np.random.rand() * X_train.shape[0])\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train[img], interpolation='none')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(\n",
    "    X_train_gray[img, :, :, 0], cmap=plt.get_cmap('gray'), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The code is credit to: \"http://www.itdadao.com/articles/c15a1243072p0.html\"\n",
    "def getHOGfeat(image,\n",
    "               stride=8,\n",
    "               orientations=8,\n",
    "               pixels_per_cell=(8, 8),\n",
    "               cells_per_block=(2, 2)):\n",
    "    cx, cy = pixels_per_cell\n",
    "    bx, by = cells_per_block\n",
    "    sx, sy, sz = image.shape\n",
    "    n_cellsx = int(np.floor(sx // cx))  # number of cells in x\n",
    "    n_cellsy = int(np.floor(sy // cy))  # number of cells in y\n",
    "    n_blocksx = (n_cellsx - bx) + 1\n",
    "    n_blocksy = (n_cellsy - by) + 1\n",
    "    gx = np.zeros((sx, sy), dtype=np.double)\n",
    "    gy = np.zeros((sx, sy), dtype=np.double)\n",
    "    eps = 1e-5\n",
    "    grad = np.zeros((sx, sy, 2), dtype=np.double)\n",
    "    for i in range(1, sx - 1):\n",
    "        for j in range(1, sy - 1):\n",
    "            gx[i, j] = image[i, j - 1] - image[i, j + 1]\n",
    "            gy[i, j] = image[i + 1, j] - image[i - 1, j]\n",
    "            grad[i, j, 0] = np.arctan(gy[i, j] / (gx[i, j] + eps)) * 180 / math.pi\n",
    "            if gx[i, j] < 0:\n",
    "                grad[i, j, 0] += 180\n",
    "            grad[i, j, 0] = (grad[i, j, 0] + 360) % 360\n",
    "            grad[i, j, 1] = np.sqrt(gy[i, j]**2 + gx[i, j]**2)\n",
    "    normalised_blocks = np.zeros((n_blocksy, n_blocksx, by * bx * orientations))\n",
    "\n",
    "    for y in range(n_blocksy):\n",
    "        for x in range(n_blocksx):\n",
    "            block = grad[y * stride:y * stride + 16, x * stride:x * stride + 16]\n",
    "            hist_block = np.zeros(32, dtype=np.double)\n",
    "            eps = 1e-5\n",
    "            for k in range(by):\n",
    "                for m in range(bx):\n",
    "                    cell = block[k * 8:(k + 1) * 8, m * 8:(m + 1) * 8]\n",
    "                    hist_cell = np.zeros(8, dtype=np.double)\n",
    "                    for i in range(cy):\n",
    "                        for j in range(cx):\n",
    "                            n = int(cell[i, j, 0] / 45)\n",
    "                            hist_cell[n] += cell[i, j, 1]\n",
    "                    hist_block[(k * bx + m) * orientations:(k * bx + m + 1) * orientations] = hist_cell[:]\n",
    "            normalised_blocks[y, x, :] = hist_block / np.sqrt(\n",
    "                hist_block.sum()**2 + eps)\n",
    "\n",
    "    return normalised_blocks.ravel()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_hog = []\n",
    "X_test_hog = []\n",
    "\n",
    "print('This will take some minutes.')\n",
    "\n",
    "for img in X_train_gray:\n",
    "    img_hog = getHOGfeat(img)\n",
    "    X_train_hog.append(img_hog)\n",
    "\n",
    "for img in X_test_gray:\n",
    "    img_hog = getHOGfeat(img)\n",
    "    X_test_hog.append(img_hog)\n",
    "\n",
    "X_train_hog_array = np.asarray(X_train_hog)\n",
    "X_test_hog_array = np.asarray(X_test_hog)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# p=2 and metric='minkowski' means the Euclidean Distance\n",
    "knn = KNeighborsClassifier(n_neighbors=11, p=2, metric='minkowski')\n",
    "\n",
    "knn.fit(X_train_hog_array, y_train.ravel())\n",
    "y_pred = knn.predict(X_test_hog_array)\n",
    "print('[KNN]')\n",
    "print('Misclassified samples: %d' % (y_test.ravel() != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# C is the hyperparameter for the error penalty term\n",
    "# gamma is the hyperparameter for the rbf kernel\n",
    "svm_linear = SVC(kernel='linear', random_state=0, gamma=0.2, C=10.0)\n",
    "\n",
    "svm_linear.fit(X_train_hog_array, y_train.ravel())\n",
    "y_pred = svm_linear.predict(X_test_hog_array)\n",
    "print('[Linear SVC]')\n",
    "print('Misclassified samples: %d' % (y_test.ravel() != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
