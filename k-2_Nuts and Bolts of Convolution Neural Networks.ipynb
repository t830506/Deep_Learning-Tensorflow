{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Pipeline\n",
    "1. The list of filenames\n",
    "2. Optional filename shuffling\n",
    "3. Optional epoch limit\n",
    "4. Filename queue\n",
    "5. A Reader for the file format\n",
    "6. A decoder for a record read by the reader\n",
    "7. Optional preprocessing\n",
    "8. Example queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unahsu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data Manually  \n",
    "To know how it works under the hood, let's load CIFAR-10 by our own (not using keras). According the descripion, the dataset file is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. We define some constants based on the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the url to download CIFAR-10 dataset (binary version)\n",
    "# see format and details here: http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "DEST_DIRECTORY = 'dataset/cifar10'\n",
    "\n",
    "# the image size we want to keep\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "IMAGE_SIZE_CROPPED = 24\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10 \n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading cifar-10-binary.tar.gz ...\n",
      ">> Total 170052171 bytes\n",
      ">> Done\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_and_extract(dest_directory, url):\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    file_name = 'cifar-10-binary.tar.gz'\n",
    "    file_path = os.path.join(dest_directory, file_name)\n",
    "    # if have not downloaded yet\n",
    "    if not os.path.exists(file_path):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r%.1f%%' % \n",
    "                             (float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()  # flush the buffer\n",
    "\n",
    "        print('>> Downloading %s ...' % file_name)\n",
    "        file_path, _ = urllib.request.urlretrieve(url, file_path, _progress)\n",
    "        file_size = os.stat(file_path).st_size\n",
    "        print('\\r>> Total %d bytes' % file_size)\n",
    "    extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        # Open for reading with gzip compression, then extract all\n",
    "        tarfile.open(file_path, 'r:gz').extractall(dest_directory)\n",
    "    print('>> Done')\n",
    "\n",
    "# download it\n",
    "maybe_download_and_extract(DEST_DIRECTORY, DATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After downloading the dataset, we create functions\n",
    "1. distort_input(training_file, batch_size) to get a training example queue.\n",
    "2. eval_input(testing_file, batch_size) to get a testing example queue.\n",
    "3. read_cifar10(filename_queue) to read a record from dataset with a filename queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the folder store the dataset\n",
    "DATA_DIRECTORY = DEST_DIRECTORY + '/cifar-10-batches-bin'\n",
    "# (1) a list of training/testing filenames\n",
    "training_files = [os.path.join(DATA_DIRECTORY, 'data_batch_%d.bin' % i) for i in range(1,6)]\n",
    "testing_files = [os.path.join(DATA_DIRECTORY, 'test_batch.bin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (5) + (6)\n",
    "def read_cifar10(filename_queue):\n",
    "    \"\"\" Reads and parses examples from CIFAR10 data files.\n",
    "        -----\n",
    "        Args:\n",
    "            filename_queue: \n",
    "                A queue of strings with the filenames to read from.\n",
    "        Returns:\n",
    "            An object representing a single example, with the following fields:\n",
    "            height: \n",
    "                number of rows in the result (32)\n",
    "            width: \n",
    "                number of columns in the result (32)\n",
    "            depth: \n",
    "                number of color channels in the result (3)\n",
    "            key: \n",
    "                a scalar string Tensor describing the filename & record number for this example.\n",
    "            label: \n",
    "                an int32 Tensor with the label in the range 0..9.\n",
    "            image: \n",
    "                a [height, width, depth] uint8 Tensor with the image data\n",
    "      \"\"\"\n",
    "\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "\n",
    "    result = CIFAR10Record()\n",
    "    # CIFAR10 consists of 60000 32x32 'color' images in 10 classes\n",
    "    label_bytes = 1  # 10 class\n",
    "    result.height = IMAGE_HEIGHT\n",
    "    result.width = IMAGE_WIDTH\n",
    "    result.depth = IMAGE_DEPTH\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "\n",
    "    # bytes of a record: label(1 byte) followed by pixels(3072 bytes)\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    \n",
    "    # (5) reader for cifar10 file format\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    # read a record\n",
    "    result.key, record_string = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    # (6) decoder\n",
    "    record_uint8 = tf.decode_raw(record_string, tf.uint8)\n",
    "    # get the label and cast it to int32\n",
    "    result.label = tf.cast(\n",
    "        tf.strided_slice(record_uint8, [0], [label_bytes]), tf.int32)\n",
    "    # [depth, height, width], uint8\n",
    "    depth_major = tf.reshape(\n",
    "        tf.strided_slice(record_uint8, [label_bytes],\n",
    "                         [label_bytes + image_bytes]),\n",
    "        [result.depth, result.height, result.width])\n",
    "    # change to [height, width, depth], uint8\n",
    "    result.image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distort_input(training_files, batch_size):\n",
    "    \"\"\" Construct distorted input for CIFAR training using the Reader ops.\n",
    "        -----\n",
    "        Args:\n",
    "            training_files: \n",
    "                an array of paths of the training files.\n",
    "            batch_size: \n",
    "                Number of images per batch.\n",
    "        Returns:\n",
    "            images: Images. \n",
    "                4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "            labels: Labels. \n",
    "                1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    for f in training_files:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "    # create a queue that produces filenames to read\n",
    "    # (4) filename queue\n",
    "    file_queue = tf.train.string_input_producer(training_files)\n",
    "    \n",
    "    # (5) + (6)\n",
    "    cifar10_record = read_cifar10(file_queue)\n",
    "    \n",
    "    # (7) image preprocessing for training\n",
    "    height = IMAGE_SIZE_CROPPED\n",
    "    width = IMAGE_SIZE_CROPPED\n",
    "    float_image = tf.cast(cifar10_record.image, tf.float32)\n",
    "    distorted_image = tf.random_crop(float_image, [height, width, 3])\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "\n",
    "    # standardization: subtract off the mean and divide by the variance of the pixels\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    distorted_image.set_shape([height, width, 3])\n",
    "    cifar10_record.label.set_shape([1])\n",
    "\n",
    "    # ensure a level of mixing of elements.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(\n",
    "        NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "\n",
    "    # (8) example queue\n",
    "    # Filling queue with min_queue_examples CIFAR images before starting to train\n",
    "    image_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [distorted_image, cifar10_record.label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=16,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples)\n",
    "    return image_batch, tf.reshape(label_batch, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_input(testing_files, batch_size):\n",
    "    for f in testing_files:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "    # create a queue that produces filenames to read\n",
    "    file_queue = tf.train.string_input_producer(testing_files)\n",
    "    cifar10_record = read_cifar10(file_queue)\n",
    "    \n",
    "    # image preprocessing for training\n",
    "    height = IMAGE_SIZE_CROPPED\n",
    "    width = IMAGE_SIZE_CROPPED\n",
    "    float_image = tf.cast(cifar10_record.image, tf.float32)\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(float_image, height, width)\n",
    "    image_eval = tf.image.per_image_standardization(resized_image)\n",
    "    image_eval.set_shape([height, width, 3])\n",
    "    cifar10_record.label.set_shape([1])\n",
    "    \n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(\n",
    "        NUM_EXAMPLES_PER_EPOCH_FOR_EVAL * min_fraction_of_examples_in_queue)\n",
    "    image_batch, label_batch = tf.train.batch(\n",
    "        [image_eval, cifar10_record.label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=16,\n",
    "        capacity=min_queue_examples + 3 * batch_size)\n",
    "    return image_batch, tf.reshape(label_batch, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test function distort_input\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    image, label = distort_input(training_files, BATCH_SIZE)\n",
    "    # --- Note ---\n",
    "    # If you forget to call start_queue_runners(), it will hang\n",
    "    # indefinitely and deadlock the user program.\n",
    "    # ------------\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    image_batch, label_batch = sess.run([image, label])\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    image_batch_np = np.asarray(image_batch)\n",
    "    label_batch_np = np.asarray(label_batch)\n",
    "    print('Shape of cropped image:', image.shape)\n",
    "    print('Shape of label:', label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_Model(object):\n",
    "    def __init__(self, batch_size, num_classes, num_training_example,\n",
    "                 num_epoch_per_decay, init_lr, moving_average_decay):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_training_example = num_training_example\n",
    "        self.num_epoch_per_decay = num_epoch_per_decay\n",
    "        self.init_lr = init_lr  # initial learn rate\n",
    "        self.moving_average_decay = moving_average_decay\n",
    "\n",
    "    def _variable_on_cpu(self, name, shape, initializer):\n",
    "        with tf.device('/cpu:0'):\n",
    "            var = tf.get_variable(\n",
    "                name, shape, initializer=initializer, dtype=tf.float32)\n",
    "        return var\n",
    "\n",
    "    def _variable_with_weight_decay(self, name, shape, stddev, wd=0.0):\n",
    "        \"\"\" Helper to create an initialized Variable with weight decay.\n",
    "            Note that the Variable is initialized with a truncated normal \n",
    "            distribution. A weight decay is added only if one is specified.\n",
    "            -----\n",
    "            Args:\n",
    "                name: \n",
    "                    name of the variable\n",
    "                shape: \n",
    "                    a list of ints\n",
    "                stddev: \n",
    "                    standard deviation of a truncated Gaussian\n",
    "                wd: \n",
    "                    add L2Loss weight decay multiplied by this float. If None, weight\n",
    "                    decay is not added for this Variable.\n",
    "            Returns:\n",
    "                Variable Tensor\n",
    "        \"\"\"\n",
    "        initializer = tf.truncated_normal_initializer(\n",
    "            stddev=stddev, dtype=tf.float32)\n",
    "        var = self._variable_on_cpu(name, shape, initializer)\n",
    "        # deal with weight decay\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    "\n",
    "    def inference(self, images):\n",
    "        \"\"\" build the model\n",
    "            -----\n",
    "            Args:\n",
    "                images with shape [batch_size,24,24,3]\n",
    "            Return:\n",
    "                logits with shape [batch_size,10]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('conv_1') as scope:\n",
    "            kernel = self._variable_with_weight_decay(\n",
    "                'weights', [5, 5, 3, 64], 5e-2)\n",
    "            conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "            biases = self._variable_on_cpu('bias', [64], tf.constant_initializer(0.0))\n",
    "            pre_activation = tf.nn.bias_add(conv, biases)\n",
    "            conv_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        # pool_1\n",
    "        pool_1 = tf.nn.max_pool(\n",
    "            conv_1,\n",
    "            ksize=[1, 3, 3, 1],\n",
    "            strides=[1, 2, 2, 1],\n",
    "            padding='SAME',\n",
    "            name='pool_1')\n",
    "        # norm_1 (local_response_normalization)\n",
    "        norm_1 = tf.nn.lrn(\n",
    "            pool_1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm_1')\n",
    "        # conv2\n",
    "        with tf.variable_scope('conv_2') as scope:\n",
    "            kernel = self._variable_with_weight_decay(\n",
    "                'weights', [5, 5, 64, 64], 5e-2)\n",
    "            conv = tf.nn.conv2d(norm_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = self._variable_on_cpu('biases', [64],\n",
    "                                           tf.constant_initializer(0.1))\n",
    "            pre_activation = tf.nn.bias_add(conv, biases)\n",
    "            conv_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        # norm2\n",
    "        norm_2 = tf.nn.lrn(\n",
    "            conv_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm_2')\n",
    "        # pool2\n",
    "        pool_2 = tf.nn.max_pool(\n",
    "            norm_2,\n",
    "            ksize=[1, 3, 3, 1],\n",
    "            strides=[1, 2, 2, 1],\n",
    "            padding='SAME',\n",
    "            name='pool_2')\n",
    "        # FC_1 (fully-connected layer)\n",
    "        with tf.variable_scope('FC_1') as scope:\n",
    "            flat_features = tf.reshape(pool_2, [self.batch_size, -1])\n",
    "            dim = flat_features.get_shape()[1].value\n",
    "            weights = self._variable_with_weight_decay(\n",
    "                'weights', [dim, 384], 0.04, 0.004)\n",
    "            biases = self._variable_on_cpu('biases', [384],\n",
    "                                           tf.constant_initializer(0.1))\n",
    "        FC_1 = tf.nn.relu(\n",
    "            tf.matmul(flat_features, weights) + biases, name=scope.name)\n",
    "        # FC_2\n",
    "        with tf.variable_scope('FC_2') as scope:\n",
    "            weights = self._variable_with_weight_decay(\n",
    "                'weights', [384, 192], 0.04, 0.004)\n",
    "            biases = self._variable_on_cpu('biases', [192],\n",
    "                                           tf.constant_initializer(0.1))\n",
    "            FC_2 = tf.nn.relu(tf.matmul(FC_1, weights) + biases, name=scope.name)\n",
    "        # softmax_linear\n",
    "        with tf.variable_scope('softmax_linear') as scope:\n",
    "            weights = self._variable_with_weight_decay(\n",
    "                'weights', [192, self.num_classes], 1 / 192.0)\n",
    "            biases = self._variable_on_cpu('biases', [self.num_classes],\n",
    "                                           tf.constant_initializer(0.0))\n",
    "            logits = tf.add(tf.matmul(FC_2, weights), biases, name=scope.name)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, logits, labels):\n",
    "        '''calculate the loss'''\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "        tf.add_to_collection('losses', cross_entropy_mean)\n",
    "        # The total loss is defined as the cross entropy loss plus all of the weight decay terms (L2 loss).\n",
    "        return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "    def train(self, total_loss, global_step):\n",
    "        '''train a step'''\n",
    "        num_batches_per_epoch = self.num_training_example / self.batch_size\n",
    "        decay_steps = int(num_batches_per_epoch * self.num_epoch_per_decay)\n",
    "        # Decay the learning rate exponentially based on the number of steps.\n",
    "        lr = tf.train.exponential_decay(\n",
    "            self.init_lr, global_step, decay_steps, decay_rate=0.1, staircase=True)\n",
    "        opt = tf.train.GradientDescentOptimizer(lr)\n",
    "        grads = opt.compute_gradients(total_loss)\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "        # Track the moving averages of all trainable variables.\n",
    "        # This step just records the moving average weights but not uses them\n",
    "        ema = tf.train.ExponentialMovingAverage(self.moving_average_decay,\n",
    "                                                global_step)\n",
    "        self.ema = ema\n",
    "        variables_averages_op = ema.apply(tf.trainable_variables())\n",
    "        with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "            train_op = tf.no_op(name='train')\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# CNN model\n",
    "model = CNN_Model(batch_size = BATCH_SIZE, \n",
    "                  num_classes = NUM_CLASSES, \n",
    "                  num_training_example = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN, \n",
    "                  num_epoch_per_decay = 350.0, \n",
    "                  init_lr = 0.1,\n",
    "                  moving_average_decay = 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# op for training\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "with tf.device('/cpu:0'):\n",
    "    images, labels = distort_input(training_files, BATCH_SIZE)\n",
    "with tf.variable_scope('model'):\n",
    "    logits = model.inference(images)\n",
    "\n",
    "total_loss = model.loss(logits, labels)\n",
    "train_op = model.train(total_loss, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 3\n",
    "NUM_BATCH_PER_EPOCH = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN // BATCH_SIZE\n",
    "ckpt_dir = './model/'\n",
    "\n",
    "# train\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if (ckpt and ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "        gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        sess.run(tf.assign(global_step, gs))\n",
    "    else:\n",
    "        # no checkpoint found\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    loss = []\n",
    "    for i in range(NUM_EPOCH):\n",
    "        _loss = []\n",
    "        for _ in range(NUM_BATCH_PER_EPOCH):\n",
    "            l, _ = sess.run([total_loss, train_op])\n",
    "            _loss.append(l)\n",
    "        loss_this_epoch = np.sum(_loss)\n",
    "        gs = global_step.eval()\n",
    "        print('loss of epoch %d: %f' % (gs / NUM_BATCH_PER_EPOCH, loss_this_epoch))\n",
    "        loss.append(loss_this_epoch)\n",
    "        saver.save(sess, ckpt_dir + 'model.ckpt', global_step=gs)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # build testing example queue\n",
    "    images, labels = eval_input(testing_files, BATCH_SIZE)\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    logits = model.inference(images)\n",
    "\n",
    "# use to calculate top-1 error\n",
    "top_k_op = tf.nn.in_top_k(logits, labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables_to_restore = model.ema.variables_to_restore()\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        num_iter = 1#NUM_EXAMPLES_PER_EPOCH_FOR_EVAL // BATCH_SIZE\n",
    "        total_sample_count = num_iter * BATCH_SIZE\n",
    "        true_count = 0\n",
    "        for _ in range(num_iter):\n",
    "            predictions = sess.run(top_k_op)\n",
    "            true_count += np.sum(predictions)\n",
    "        print('Accurarcy: %d/%d = %f' % (true_count, total_sample_count,\n",
    "                                         true_count / total_sample_count))\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    else:\n",
    "        print('train first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
