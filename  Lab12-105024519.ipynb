{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lab12_util import *\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "DEST_DIRECTORY = 'dataset/cifar10'\n",
    "DATA_DIRECTORY = DEST_DIRECTORY + '/cifar-10-batches-bin'\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "IMAGE_SIZE_CROPPED = 24\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10 \n",
    "LABEL_BYTES = 1\n",
    "IMAGE_BYTES = 32 * 32 * 3\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# download it\n",
    "maybe_download_and_extract(DEST_DIRECTORY, DATA_URL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from tensorflow.contrib.data import FixedLengthRecordDataset, Iterator\n",
    "\n",
    "def cifar10_record_distort_parser(record):\n",
    "    ''' Parse the record into label, cropped and distorted image\n",
    "        -----\n",
    "        Args:\n",
    "            record: \n",
    "                a record containing label and image.\n",
    "        Returns:\n",
    "            label: \n",
    "                the label in the record.\n",
    "            image: \n",
    "                the cropped and distorted image in the record.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cifar10_record_crop_parser(record):\n",
    "    ''' Parse the record into label, cropped image\n",
    "        -----\n",
    "        Args:\n",
    "            record: \n",
    "                a record containing label and image.\n",
    "        Returns:\n",
    "            label: \n",
    "                the label in the record.\n",
    "            image: \n",
    "                the cropped image in the record.\n",
    "    '''\n",
    "    # TODO2\n",
    "    pass\n",
    "\n",
    "\n",
    "def cifar10_iterator(filenames, batch_size, cifar10_record_parser):\n",
    "    ''' Create a dataset and return a tf.contrib.data.Iterator \n",
    "        which provides a way to extract elements from this dataset.\n",
    "        -----\n",
    "        Args:\n",
    "            filenames: \n",
    "                a tensor of filenames.\n",
    "            batch_size: \n",
    "                batch size.\n",
    "        Returns:\n",
    "            iterator: \n",
    "                an Iterator providing a way to extract elements from the created dataset.\n",
    "            output_types: \n",
    "                the output types of the created dataset.\n",
    "            output_shapes: \n",
    "                the output shapes of the created dataset.\n",
    "    '''\n",
    "    record_bytes = LABEL_BYTES + IMAGE_BYTES\n",
    "    dataset = FixedLengthRecordDataset(filenames, record_bytes)\n",
    "    # TODO3\n",
    "    # tips: use dataset.map with cifar10_record_parser(record)\n",
    "    #       output_types = dataset.output_types\n",
    "    #       output_shapes = dataset.output_shapes\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "training_files = [os.path.join(DATA_DIRECTORY, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n",
    "testing_files = [os.path.join(DATA_DIRECTORY, 'test_batch.bin')]\n",
    "\n",
    "filenames_train = tf.constant(training_files)\n",
    "filenames_test = tf.constant(testing_files)\n",
    "\n",
    "iterator_train, types, shapes = cifar10_iterator(filenames_train, BATCH_SIZE,\n",
    "                                                 cifar10_record_distort_parser)\n",
    "iterator_test, _, _ = cifar10_iterator(filenames_test, BATCH_SIZE,\n",
    "                                       cifar10_record_crop_parser)\n",
    "\n",
    "# use to handle training and testing\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = Iterator.from_string_handle(handle, types, shapes)\n",
    "labels_images_pairs = iterator.get_next()\n",
    "\n",
    "# CNN model\n",
    "model = CNN_Model(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_training_example=NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN,\n",
    "    num_epoch_per_decay=350.0,\n",
    "    init_lr=0.1,\n",
    "    moving_average_decay=0.9999)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    labels, images = labels_images_pairs\n",
    "    labels = tf.reshape(labels, [BATCH_SIZE])\n",
    "    images = tf.reshape(\n",
    "        images, [BATCH_SIZE, IMAGE_SIZE_CROPPED, IMAGE_SIZE_CROPPED, IMAGE_DEPTH])\n",
    "with tf.variable_scope('model'):\n",
    "    logits = model.inference(images)\n",
    "\n",
    "# train\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "total_loss = model.loss(logits, labels)\n",
    "train_op = model.train(total_loss, global_step)\n",
    "# test\n",
    "top_k_op = tf.nn.in_top_k(logits, labels, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/blob/master/official/resnet/cifar10_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unahsu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Runs a ResNet model on the CIFAR-10 dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "_BATCH_SIZE = 128\n",
    "_HEIGHT = 32\n",
    "_WIDTH = 32\n",
    "_DEPTH = 3\n",
    "_IMAGE_SIZE_CROPPED = 24\n",
    "_NUM_CLASSES = 10\n",
    "_NUM_DATA_FILES = 5\n",
    "_NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "_NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "_NUM_IMAGES = {'train'     : _NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN,\n",
    "               'validation': _NUM_EXAMPLES_PER_EPOCH_FOR_EVAL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def record_dataset(filenames):\n",
    "    \"\"\"Returns an input pipeline Dataset from `filenames`.\"\"\"\n",
    "    record_bytes = _HEIGHT * _WIDTH * _DEPTH + 1\n",
    "    return tf.data.FixedLengthRecordDataset(filenames, record_bytes)\n",
    "\n",
    "\n",
    "def get_filenames(is_training, data_dir):\n",
    "    \"\"\"Returns a list of filenames.\"\"\"\n",
    "    data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\n",
    "\n",
    "    assert os.path.exists(data_dir), (\n",
    "        'Run cifar10_download_and_extract.py first to download and extract the CIFAR-10 data.')\n",
    "\n",
    "    if is_training:\n",
    "        return [\n",
    "            os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "            for i in range(1, _NUM_DATA_FILES + 1)\n",
    "        ]\n",
    "    else:\n",
    "        return [os.path.join(data_dir, 'test_batch.bin')]\n",
    "\n",
    "\n",
    "def parse_record(raw_record):\n",
    "    \"\"\"Parse CIFAR-10 image and label from a raw record.\"\"\"\n",
    "    # Every record consists of a label followed by the image, with a fixed number of bytes for each.\n",
    "    label_bytes = 1\n",
    "    image_bytes = _HEIGHT * _WIDTH * _DEPTH\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    # Convert bytes to a vector of uint8 that is record_bytes long.\n",
    "    record_vector = tf.decode_raw(raw_record, tf.uint8)\n",
    "\n",
    "    # The first byte represents the label, which we convert from uint8 to int32 and then to one-hot.\n",
    "    label = tf.cast(record_vector[0], tf.int32)\n",
    "#    label = tf.one_hot(label, _NUM_CLASSES)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "        record_vector[label_bytes:record_bytes], [_DEPTH, _HEIGHT, _WIDTH])\n",
    "\n",
    "    # Convert from [depth, height, width] to [height, width, depth], and cast as float32.\n",
    "    image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def preprocess_image(image, is_training):\n",
    "    \"\"\"Preprocess a single image of layout [height, width, depth].\"\"\"\n",
    "    if is_training:\n",
    "        # Resize the image to add four extra pixels on each side.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(\n",
    "            image, _HEIGHT + 8, _WIDTH + 8)\n",
    "\n",
    "        # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n",
    "        height = _IMAGE_SIZE_CROPPED\n",
    "        width = _IMAGE_SIZE_CROPPED\n",
    "        image = tf.random_crop(image, [height, width, _DEPTH])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "    else:\n",
    "        # image preprocessing like training\n",
    "        height = _IMAGE_SIZE_CROPPED\n",
    "        width = _IMAGE_SIZE_CROPPED\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image, height, width)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def input_fn(is_training, data_dir, batch_size):\n",
    "    \"\"\"Input_fn using the tf.data input pipeline for CIFAR-10 dataset.\n",
    "        Args:\n",
    "            is_training: A boolean denoting whether the input is for training.\n",
    "            data_dir: The directory containing the input data.\n",
    "            batch_size: The number of samples per batch.\n",
    "            num_epochs: The number of epochs to repeat the dataset.\n",
    "        Returns:\n",
    "            A tuple of images and labels.\n",
    "    \"\"\"\n",
    "    dataset = record_dataset(get_filenames(is_training, data_dir))\n",
    "\n",
    "    if is_training:\n",
    "        # When choosing shuffle buffer sizes, larger sizes result in better randomness,\n",
    "        # while smaller sizes have better performance. Because CIFAR-10 is a relatively small dataset,\n",
    "        # we choose to shuffle the full epoch.\n",
    "        dataset = dataset.shuffle(buffer_size=_NUM_IMAGES['train'])\n",
    "\n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.map(lambda image, label: (preprocess_image(image, is_training), label))\n",
    "\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate epochs from blending together.\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # Batch results by up to batch_size, and then fetch the tuple from the iterator.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterator = input_fn(is_training = True,\n",
    "                    batch_size = _BATCH_SIZE,\n",
    "                    data_dir = 'dataset/cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 24, 24, 3)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    next_batch = iterator.get_next()\n",
    "    data, label = sess.run(next_batch)\n",
    "    print(data.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lab12_util import *\n",
    "from tensorflow.contrib.data import FixedLengthRecordDataset, Iterator\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Generate labels_images_pairs\n",
    "iterator_train = input_fn(\n",
    "    is_training=True, batch_size=_BATCH_SIZE, data_dir='dataset/cifar10')\n",
    "labels_images_pairs = iterator_train.get_next()\n",
    "\n",
    "# CNN model\n",
    "model = CNN_Model(\n",
    "    batch_size = _BATCH_SIZE,\n",
    "    num_classes = _NUM_CLASSES,\n",
    "    num_training_example = _NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN,\n",
    "    num_epoch_per_decay = 350.0,\n",
    "    init_lr = 0.1,\n",
    "    moving_average_decay = 0.9999)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    images, labels = labels_images_pairs\n",
    "    images = tf.reshape(images, [_BATCH_SIZE, 24, 24, _DEPTH])\n",
    "    labels = tf.reshape(labels, [_BATCH_SIZE])\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    logits = model.inference(images)\n",
    "\n",
    "# train\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "total_loss = model.loss(logits, labels)\n",
    "train_op = model.train(total_loss, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 , Avg. Training loss: 1561.5322 , Spend 258.4264 sec\n",
      "Epoch 1/10 , Avg. Training loss: 1255.9395 , Spend 261.4649 sec\n",
      "Epoch 2/10 , Avg. Training loss: 1053.4154 , Spend 241.4004 sec\n",
      "Epoch 3/10 , Avg. Training loss: 901.7992 , Spend 240.0456 sec\n",
      "Epoch 4/10 , Avg. Training loss: 788.4717 , Spend 236.6721 sec\n",
      "Epoch 5/10 , Avg. Training loss: 706.6742 , Spend 236.3431 sec\n",
      "Epoch 6/10 , Avg. Training loss: 643.5648 , Spend 236.3495 sec\n",
      "Epoch 7/10 , Avg. Training loss: 597.1235 , Spend 237.3216 sec\n",
      "Epoch 8/10 , Avg. Training loss: 560.1920 , Spend 236.5734 sec\n",
      "Epoch 9/10 , Avg. Training loss: 531.8333 , Spend 236.5790 sec\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "_NUM_EPOCH = 10\n",
    "_NUM_BATCH_PER_EPOCH = _NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN // _BATCH_SIZE\n",
    "ckpt_dir = './model1/'\n",
    "\n",
    "# train\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if (ckpt and ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "        gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        sess.run(tf.assign(global_step, gs))\n",
    "    else:\n",
    "        # no checkpoint found\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    loss = []\n",
    "    for i in range(_NUM_EPOCH):\n",
    "        start = time.time()\n",
    "        _loss = []\n",
    "        for _ in range(_NUM_BATCH_PER_EPOCH):\n",
    "            l, _ = sess.run([total_loss, train_op])\n",
    "            _loss.append(l)\n",
    "\n",
    "        end = time.time()\n",
    "        loss_this_epoch = np.sum(_loss)\n",
    "        gs = global_step.eval()\n",
    "        print (\"Epoch {}/{}\".format(i, _NUM_EPOCH),\n",
    "               \", Avg. Training loss: {:.4f}\".format(loss_this_epoch),\n",
    "               \", Spend {:.4f} sec\".format(end-start))\n",
    "\n",
    "        loss.append(loss_this_epoch)\n",
    "        saver.save(sess, ckpt_dir + 'model.ckpt', global_step=gs)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 24, 24, 3)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "iterator = input_fn(is_training = False,\n",
    "                    batch_size = _BATCH_SIZE,\n",
    "                    data_dir = 'dataset/cifar10')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    next_batch = iterator.get_next()\n",
    "    data, label = sess.run(next_batch)\n",
    "    print(data.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator_test = input_fn(\n",
    "    is_training=False, batch_size=_BATCH_SIZE, data_dir='dataset/cifar10')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # build testing example queue\n",
    "    images, labels = iterator_test.get_next()\n",
    "    images = tf.reshape(images, [_BATCH_SIZE, 24, 24, _DEPTH])\n",
    "    labels = tf.reshape(labels, [_BATCH_SIZE])\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    logits = model.inference(images)\n",
    "\n",
    "# use to calculate top-1 error\n",
    "top_k_op = tf.nn.in_top_k(logits, labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model1/model.ckpt-3900\n",
      "Iteration: 0/78 \n",
      "Iteration: 10/78 \n",
      "Iteration: 20/78 \n",
      "Iteration: 30/78 \n",
      "Iteration: 40/78 \n",
      "Iteration: 50/78 \n",
      "Iteration: 60/78 \n",
      "Iteration: 70/78 \n",
      "Accurarcy: 6892/9984 = 0.690304 , Spend 13.9689 sec\n"
     ]
    }
   ],
   "source": [
    "num_iter = _NUM_EXAMPLES_PER_EPOCH_FOR_EVAL // _BATCH_SIZE\n",
    "total_sample_count = num_iter * _BATCH_SIZE\n",
    "\n",
    "variables_to_restore = model.ema.variables_to_restore()\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        start = time.time()\n",
    "        true_count = 0\n",
    "        for _ in range(num_iter):\n",
    "            predictions = sess.run(top_k_op)\n",
    "            true_count += np.sum(predictions)\n",
    "            if _ % 10 == 0:\n",
    "                print ('Iteration: %d/%d ' % (_, num_iter))\n",
    "        end = time.time()\n",
    "        print('Accurarcy: %d/%d = %f' % (true_count, total_sample_count,\n",
    "                                         true_count / total_sample_count),\n",
    "              \", Spend {:.4f} sec\".format(end-start))\n",
    "    else:\n",
    "        print('train first')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "#with train_graph.as_default():\n",
    "#    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess: #graph=train_graph\n",
    "    epoch_loss = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        start = time.time()\n",
    "        for _ in range(int(_NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN/_BATCH_SIZE)):\n",
    "            print (images.shape, labels.shape)\n",
    "            feed = {images: images,\n",
    "                    labels: labels }\n",
    "            train_loss, _ = sess.run([total_loss, train_op], feed_dict=feed)\n",
    "            epoch_loss += train_loss\n",
    "        end = time.time()\n",
    "        print (\"Epoch {}/{}\".format(e, epochs),\n",
    "               \"Avg. Training loss: {:.4f}\".format(loss),\n",
    "               \"{:.4f} sec\".format(end-start))\n",
    "        start = time.time()\n",
    "\n",
    "#    save_path = saver.save(sess, \"model1/datasetapi.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
